{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVUDcFOnMaL3",
        "outputId": "c1249828-1f69-4c37-9c39-1f089e3f6cc2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain_community\n",
            "  Downloading langchain_community-0.3.24-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.16-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting langchain-anthropic\n",
            "  Downloading langchain_anthropic-0.3.13-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.3-py3-none-any.whl.metadata (7.9 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.59 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.59)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (6.0.2)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (3.11.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain_community)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (0.3.42)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain_community)\n",
            "  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.68.2 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.78.0)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.9.0)\n",
            "Collecting anthropic<1,>=0.51.0 (from langchain-anthropic)\n",
            "  Downloading anthropic-0.51.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-anthropic) (2.11.4)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Collecting langgraph-checkpoint<3.0.0,>=2.0.10 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting langgraph-prebuilt>=0.1.8 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.1.8-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.69-py3-none-any.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.20.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.51.0->langchain-anthropic) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.51.0->langchain-anthropic) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.25.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.51.0->langchain-anthropic) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.51.0->langchain-anthropic) (0.9.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.51.0->langchain-anthropic) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.10 in /usr/local/lib/python3.11/dist-packages (from anthropic<1,>=0.51.0->langchain-anthropic) (4.13.2)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.59->langchain_community) (24.2)\n",
            "Collecting ormsgpack<2.0.0,>=1.8.0 (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph)\n",
            "  Downloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.68.2->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain-anthropic) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain_community)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain_community) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.2.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.25.0->anthropic<1,>=0.51.0->langchain-anthropic) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.25.0->anthropic<1,>=0.51.0->langchain-anthropic) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.59->langchain_community) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.3.24-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m44.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-0.3.16-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_anthropic-0.3.13-py3-none-any.whl (26 kB)\n",
            "Downloading langgraph-0.4.3-py3-none-any.whl (151 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.2/151.2 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading anthropic-0.51.0-py3-none-any.whl (263 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
            "Downloading langgraph_checkpoint-2.0.25-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.1.8-py3-none-any.whl (25 kB)\n",
            "Downloading langgraph_sdk-0.1.69-py3-none-any.whl (48 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.9/48.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.9.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: python-dotenv, ormsgpack, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, langgraph-sdk, dataclasses-json, anthropic, langgraph-checkpoint, langchain-openai, langchain-anthropic, langgraph-prebuilt, langgraph, langchain_community\n",
            "Successfully installed anthropic-0.51.0 dataclasses-json-0.6.7 httpx-sse-0.4.0 langchain-anthropic-0.3.13 langchain-openai-0.3.16 langchain_community-0.3.24 langgraph-0.4.3 langgraph-checkpoint-2.0.25 langgraph-prebuilt-0.1.8 langgraph-sdk-0.1.69 marshmallow-3.26.1 mypy-extensions-1.1.0 ormsgpack-1.9.1 pydantic-settings-2.9.1 python-dotenv-1.1.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "! pip install -U langchain_community langchain-openai langchain-anthropic langchain langgraph"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders.recursive_url_loader import RecursiveUrlLoader\n",
        "\n",
        "\n",
        "import os\n",
        "\n",
        "# Replace the following variables with your OpenAI details\n",
        "os.environ[\"OPENAI_API_KEY\"] = \"REPLACE_YOUR_KEY_HERE\"\n"
      ],
      "metadata": {
        "id": "OxN43ZwoMkeo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI( model=\"gpt-4o\",   temperature=0 )\n",
        "\n",
        "concatenated_content = \"\"\"\n",
        "import argparse\n",
        "import sys\n",
        "import time\n",
        "from kubernetes import client, config, watch\n",
        "from kubernetes.client.rest import ApiException\n",
        "\n",
        "# Load kubeconfig (~/.kube/config) or in-cluster config\n",
        "try:\n",
        "    config.load_kube_config()\n",
        "except Exception:\n",
        "    config.load_incluster_config()\n",
        "\n",
        "core_v1 = client.CoreV1Api()\n",
        "apps_v1 = client.AppsV1Api()\n",
        "batch_v1 = client.BatchV1Api()\n",
        "\n",
        "\n",
        "def list_pods(namespace=None):\n",
        "    #List all pods, optionally in a specific namespace\n",
        "    print(f\"Listing pods in namespace: {namespace or 'all'}\")\n",
        "    pods = core_v1.list_pod_for_all_namespaces() if not namespace else core_v1.list_namespaced_pod(namespace)\n",
        "    for pod in pods.items:\n",
        "        print(f\"{pod.status.pod_ip}\\t{pod.metadata.namespace}\\t{pod.metadata.name}\")\n",
        "\n",
        "\n",
        "def list_services(namespace=None):\n",
        "    #List services in a namespace or across all namespaces\n",
        "    print(f\"Listing services in namespace: {namespace or 'all'}\")\n",
        "    svcs = core_v1.list_service_for_all_namespaces() if not namespace else core_v1.list_namespaced_service(namespace)\n",
        "    for svc in svcs.items:\n",
        "        print(f\"{svc.metadata.namespace}\\t{svc.metadata.name}\\t{svc.spec.type}\\t{svc.spec.cluster_ip}\")\n",
        "\n",
        "\n",
        "def create_namespace(name):\n",
        "    #Create a new namespace\n",
        "    ns_body = client.V1Namespace(metadata=client.V1ObjectMeta(name=name))\n",
        "    try:\n",
        "        core_v1.create_namespace(ns_body)\n",
        "        print(f\"Namespace '{name}' created.\")\n",
        "    except ApiException as e:\n",
        "        print(f\"Failed to create namespace: {e}\")\n",
        "\n",
        "\n",
        "def delete_namespace(name):\n",
        "    #Delete a namespace\n",
        "    try:\n",
        "        core_v1.delete_namespace(name)\n",
        "        print(f\"Namespace '{name}' deletion initiated.\")\n",
        "    except ApiException as e:\n",
        "        print(f\"Failed to delete namespace: {e}\")\n",
        "\n",
        "\n",
        "def create_deployment(name, image, replicas, namespace='default'):\n",
        "    #Create a Deployment in the specified namespace\n",
        "    container = client.V1Container(\n",
        "        name=name,\n",
        "        image=image,\n",
        "        ports=[client.V1ContainerPort(container_port=80)]\n",
        "    )\n",
        "    template = client.V1PodTemplateSpec(\n",
        "        metadata=client.V1ObjectMeta(labels={'app': name}),\n",
        "        spec=client.V1PodSpec(containers=[container])\n",
        "    )\n",
        "    spec = client.V1DeploymentSpec(\n",
        "        replicas=replicas,\n",
        "        template=template,\n",
        "        selector={'matchLabels': {'app': name}}\n",
        "    )\n",
        "    deployment = client.V1Deployment(\n",
        "        metadata=client.V1ObjectMeta(name=name),\n",
        "        spec=spec\n",
        "    )\n",
        "    try:\n",
        "        apps_v1.create_namespaced_deployment(namespace=namespace, body=deployment)\n",
        "        print(f\"Deployment '{name}' created in namespace '{namespace}'.\")\n",
        "    except ApiException as e:\n",
        "        print(f\"Failed to create deployment: {e}\")\n",
        "\n",
        "\n",
        "def scale_deployment(name, replicas, namespace='default'):\n",
        "    #Scale an existing Deployment\n",
        "    body = {'spec': {'replicas': replicas}}\n",
        "    try:\n",
        "        apps_v1.patch_namespaced_deployment(name=name, namespace=namespace, body=body)\n",
        "        print(f\"Deployment '{name}' scaled to {replicas} replicas.\")\n",
        "    except ApiException as e:\n",
        "        print(f\"Failed to scale deployment: {e}\")\n",
        "\n",
        "\n",
        "def get_pod_logs(name, namespace='default', tail_lines=100):\n",
        "    #Fetch logs from a Pod\n",
        "    try:\n",
        "        logs = core_v1.read_namespaced_pod_log(name=name, namespace=namespace, tail_lines=tail_lines)\n",
        "        print(f\"Logs from {name} (last {tail_lines} lines):\\n{logs}\")\n",
        "    except ApiException as e:\n",
        "        print(f\"Failed to fetch logs: {e}\")\n",
        "\n",
        "\n",
        "def exec_command_in_pod(name, namespace='default', command=['/bin/sh', '-c', 'ls']):\n",
        "    #Execute a command in a Pod and return the output\n",
        "    try:\n",
        "        resp = stream(core_v1.connect_get_namespaced_pod_exec,\n",
        "                      name, namespace,\n",
        "                      command=command,\n",
        "                      stderr=True, stdin=False,\n",
        "                      stdout=True, tty=False)\n",
        "        print(f\"Command output:\\n{resp}\")\n",
        "    except ApiException as e:\n",
        "        print(f\"Exec failed: {e}\")\n",
        "\n",
        "\n",
        "list_pods()\n",
        "list_services('default')\n",
        "create_namespace(\"amdocsdemo1\")\n",
        "create_deployment(\"httpdemo2\", \"httpd\", 3)\n",
        "time.sleep(30)\n",
        "list_pods()\n",
        "scale_deployment(\"httpdemo2\", 5)\n",
        "list_pods()\n",
        "\n",
        "pod_name = \"REPLACE_POD_NAME_HERE\"\n",
        "exec_command_in_pod(pod_name, command=['/bin/sh', '-c', 'mkdir /hello'])\n",
        "get_pod_logs(pod_name)\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wl9kRqASMwnj",
        "outputId": "c2f7c6ec-af5c-4f54-fab9-fce0a0a1c6a2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-189a747fd535>:3: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
            "  llm = ChatOpenAI( model=\"gpt-4o\",   temperature=0 )\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Now start the langchain pydantic\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field\n",
        "\n",
        "### OpenAI\n",
        "\n",
        "# Grader prompt\n",
        "code_gen_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        (\n",
        "            \"system\",\n",
        "            \"\"\"You are a coding assistant with expertise in Kubernetes Python SDK. \\n\n",
        "    Here is a sample python Kubernetes code:  \\n ------- \\n  {context} \\n ------- \\n Answer the user\n",
        "    question based on the above provided sample code. Ensure any code you provide can be executed \\n\n",
        "    with all required imports and variables defined. Structure your answer as json with a description of the code solution. \\n\n",
        "    Then list the import statements. And finally generate the functioning code block. Here is the user question:\"\"\",\n",
        "        ),\n",
        "        (\"placeholder\", \"{messages}\"),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "uTlAh4LhMww6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Data model\n",
        "class code(BaseModel):\n",
        "    \"\"\"Code output\"\"\"\n",
        "\n",
        "    description: str = Field(description=\"Description of the problem and approach\")\n",
        "    imports: str = Field(description=\"Code block import statements\")\n",
        "    code: str = Field(description=\"Code block not including import statements\")\n",
        "\n"
      ],
      "metadata": {
        "id": "xtS5kotDMw1B"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "# Use .bind(response_format={\"type\": \"json_object\"}) instead of with_structured_output\n",
        "code_gen_chain = code_gen_prompt | llm.bind(response_format={\"type\": \"json_object\"})\n",
        "question = \"How to create a deployment with name dep2, 2 replicas and image is nginx?\"\n",
        "\n",
        "solution_json_str = code_gen_chain.invoke({\"context\":concatenated_content,\"messages\":[(\"user\",question)]})\n",
        "\n",
        "# Parse the JSON string response into the Pydantic model\n",
        "# We need to extract the content from the AIMessage object\n",
        "solution_data = json.loads(solution_json_str.content)\n"
      ],
      "metadata": {
        "id": "9f2LYfLDNXd8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(solution_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "okf1Z4yoOVhx",
        "outputId": "79eefbae-543c-4bf9-b6ca-0ea4f994c18b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'description': \"To create a deployment named 'dep2' with 2 replicas using the 'nginx' image, you can use the `create_deployment` function from the provided sample code. This function constructs a deployment object with the specified parameters and uses the Kubernetes Python client to create the deployment in the specified namespace. In this example, the deployment will be created in the 'default' namespace.\", 'imports': ['from kubernetes import client, config', 'from kubernetes.client.rest import ApiException'], 'code': 'def create_deployment(name, image, replicas, namespace=\\'default\\'):\\n    # Create a Deployment in the specified namespace\\n    container = client.V1Container(\\n        name=name,\\n        image=image,\\n        ports=[client.V1ContainerPort(container_port=80)]\\n    )\\n    template = client.V1PodTemplateSpec(\\n        metadata=client.V1ObjectMeta(labels={\\'app\\': name}),\\n        spec=client.V1PodSpec(containers=[container])\\n    )\\n    spec = client.V1DeploymentSpec(\\n        replicas=replicas,\\n        template=template,\\n        selector={\\'matchLabels\\': {\\'app\\': name}}\\n    )\\n    deployment = client.V1Deployment(\\n        metadata=client.V1ObjectMeta(name=name),\\n        spec=spec\\n    )\\n    try:\\n        apps_v1.create_namespaced_deployment(namespace=namespace, body=deployment)\\n        print(f\"Deployment \\'{name}\\' created in namespace \\'{namespace}\\'.\")\\n    except ApiException as e:\\n        print(f\"Failed to create deployment: {e}\")\\n\\n# Load kubeconfig (~/.kube/config) or in-cluster config\\ntry:\\n    config.load_kube_config()\\nexcept Exception:\\n    config.load_incluster_config()\\n\\napps_v1 = client.AppsV1Api()\\n\\n# Create the deployment\\ncreate_deployment(name=\\'dep2\\', image=\\'nginx\\', replicas=2)'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(solution_data['description'])\n",
        "\n",
        "print(solution_data['imports'])\n",
        "\n",
        "print(solution_data['code'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4L63mhyOqFJ",
        "outputId": "0cf9d74e-a69b-4870-cfcd-9a598eb3eb49"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "To create a deployment named 'dep2' with 2 replicas using the 'nginx' image, you can use the `create_deployment` function from the provided sample code. This function constructs a deployment object with the specified parameters and uses the Kubernetes Python client to create the deployment in the specified namespace. In this example, the deployment will be created in the 'default' namespace.\n",
            "['from kubernetes import client, config', 'from kubernetes.client.rest import ApiException']\n",
            "def create_deployment(name, image, replicas, namespace='default'):\n",
            "    # Create a Deployment in the specified namespace\n",
            "    container = client.V1Container(\n",
            "        name=name,\n",
            "        image=image,\n",
            "        ports=[client.V1ContainerPort(container_port=80)]\n",
            "    )\n",
            "    template = client.V1PodTemplateSpec(\n",
            "        metadata=client.V1ObjectMeta(labels={'app': name}),\n",
            "        spec=client.V1PodSpec(containers=[container])\n",
            "    )\n",
            "    spec = client.V1DeploymentSpec(\n",
            "        replicas=replicas,\n",
            "        template=template,\n",
            "        selector={'matchLabels': {'app': name}}\n",
            "    )\n",
            "    deployment = client.V1Deployment(\n",
            "        metadata=client.V1ObjectMeta(name=name),\n",
            "        spec=spec\n",
            "    )\n",
            "    try:\n",
            "        apps_v1.create_namespaced_deployment(namespace=namespace, body=deployment)\n",
            "        print(f\"Deployment '{name}' created in namespace '{namespace}'.\")\n",
            "    except ApiException as e:\n",
            "        print(f\"Failed to create deployment: {e}\")\n",
            "\n",
            "# Load kubeconfig (~/.kube/config) or in-cluster config\n",
            "try:\n",
            "    config.load_kube_config()\n",
            "except Exception:\n",
            "    config.load_incluster_config()\n",
            "\n",
            "apps_v1 = client.AppsV1Api()\n",
            "\n",
            "# Create the deployment\n",
            "create_deployment(name='dep2', image='nginx', replicas=2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "V_hl1EAQMza0",
        "outputId": "242a3b13-3125-4296-b454-7b6477f97277"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7935a8309a4a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcode_gen_chain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode_gen_prompt\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mllm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_structured_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mquestion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"How to create a deployment with name dep2, 2 replicas and image is nginx?\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0msolution\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode_gen_chain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minvoke\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m\"context\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mconcatenated_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"messages\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"user\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mwith_structured_output\u001b[0;34m(self, schema, include_raw, **kwargs)\u001b[0m\n\u001b[1;32m   1449\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1451\u001b[0;31m         llm = self.bind_tools(\n\u001b[0m\u001b[1;32m   1452\u001b[0m             \u001b[0;34m[\u001b[0m\u001b[0mschema\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m             \u001b[0mtool_choice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"any\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/langchain_core/language_models/chat_models.py\u001b[0m in \u001b[0;36mbind_tools\u001b[0;34m(self, tools, tool_choice, **kwargs)\u001b[0m\n\u001b[1;32m   1323\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mRunnable\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0ma\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \"\"\"\n\u001b[0;32m-> 1325\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m     def with_structured_output(\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: "
          ]
        }
      ]
    }
  ]
}